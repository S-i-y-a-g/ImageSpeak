# Image Captioning Model â€“ Empowering the Visually Impaire
- This project is a deep learning-based Image Captioning System developed to help visually impaired individuals understand and interpret images through automatically generated textual descriptions.
- By converting image content into descriptive captions, the model aims to enhance accessibility and provide context from visual information in a language format.

  

 # :rocket: Features
- ðŸ§¾ Caption Generation: Automatically generates human-like captions for input images.
- ðŸ§  LSTM + CNN Encoder-Decoder Architecture: Combines visual understanding and sequential prediction for accurate descriptions.
- ðŸ“¦ Pre-extracted Image Features: Efficient feature extraction using pretrained VGG16 model.

  


# :rocket: Dataset
- Flickr8k Dataset (https://www.kaggle.com/datasets/adityajn105/flickr8k)
- ~8,000 images
- Each image has 5 human-written captions
- Preprocessing includes:
- Tokenization & Vocabulary creation
- Padding sequences
- Mapping image features and captions



  


